# To support generation with probabilities instead of logits

model/transformers
1. generation_logits_process.py: line 117 -float("inf") -> 0; (Deprecated, conflict with 5,6,7,8)
2. generation_logits_process.py: line 192 sorted_logits.softmax(dim=-1).cumsum(dim=-1) -> sorted_logits.cumsum(dim=-1); (Deprecated, conflict with 5,6,7,8)
3. generation_utils.py: line 534 warpers.append(TopPLogitsWarper(top_p=top_p, min_tokens_to_keep=(2 if num_beams > 1 else 1))) -> warpers.append(TopPLogitsWarper(top_p=top_p, filter_value=0, min_tokens_to_keep=(2 if num_beams > 1 else 1))); (Deprecated, conflict with 5,6,7,8)
4. generation_utils.py: line 1410 F.softmax(next_token_scores, dim=-1) -> next_token_scores; (Deprecated, conflict with 5,6)

model/
5. generation_utils.py: Add line 1196 next_token_scores = torch.log(next_token_logits);
6. generation_utils.py: line 1216 next_token_scores = logits_processor(input_ids, next_token_logits) -> next_token_scores = logits_processor(input_ids, next_token_scores);
5. generation_utils.py: Add line 1407 next_token_scores = torch.log(next_token_logits);
6. generation_utils.py: line 1411 next_token_scores = logits_processor(input_ids, next_token_logits) -> next_token_scores = logits_processor(input_ids, next_token_scores);
7. generation_utils.py: line 1640 F.log_softmax(next_token_logits, dim=-1) -> torch.log(next_token_logits);
8. generation_utils.py: line 1895 F.log_softmax(next_token_logits, dim=-1) -> torch.log(next_token_logits);